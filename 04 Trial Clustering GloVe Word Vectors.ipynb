{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "import sklearn\n",
    "from sklearn import cross_validation\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "from scipy import stats\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "\n",
    "reload(sys)\n",
    "sys.setdefaultencoding(\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(raw_text):\n",
    "    review_text = BeautifulSoup(raw_text).get_text()\n",
    "    words = review_text.lower().split()\n",
    "    return(\" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to create bags of centroids\n",
    "def create_bag_of_centroids( wordlist, word_centroid_map ):\n",
    "    #\n",
    "    # The number of clusters is equal to the highest cluster index\n",
    "    # in the word / centroid map\n",
    "    num_centroids = max( word_centroid_map.values() ) + 1\n",
    "    #\n",
    "    # Pre-allocate the bag of centroids vector (for speed)\n",
    "    bag_of_centroids = np.zeros( num_centroids, dtype=\"float32\" )\n",
    "    #\n",
    "    # Loop over the words in the review. If the word is in the vocabulary,\n",
    "    # find which cluster it belongs to, and increment that cluster count\n",
    "    # by one\n",
    "    for word in wordlist:\n",
    "        if word in word_centroid_map:\n",
    "            index = word_centroid_map[word]\n",
    "            bag_of_centroids[index] += 1\n",
    "    #\n",
    "    # Return the \"bag of centroids\"\n",
    "    return bag_of_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting a Glove Model\n",
    "model_files = [\"new.glove.twitter.27B.25d.txt\", \"new.glove.twitter.27B.50d.txt\", \n",
    "               \"new.glove.twitter.27B.100d.txt\", \"new.glove.twitter.27B.200d.txt\"]\n",
    "list_of_num_features = [25, 50, 100, 200]\n",
    "\n",
    "languages = [\"english\"]\n",
    "datafiles = [\"summary-english-truth.txt\"]\n",
    "tasks = [\"age\", \"gender\"]\n",
    "scoring_function = 'accuracy'\n",
    "all_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_file = \"new.glove.twitter.27B.25d.txt\"\n",
    "model = gensim.models.Word2Vec.load_word2vec_format(model_file,binary=False)\n",
    "\n",
    "# ****** Run k-means on the word vectors and print a few clusters\n",
    "#\n",
    "\n",
    "start = time.time() # Start time\n",
    "\n",
    "# Set \"k\" (num_clusters) to be 1/5th of the vocabulary size, or an\n",
    "# average of 5 words per cluster\n",
    "\n",
    "avg_word_per_cluster = 100\n",
    "word_vectors = model.syn0\n",
    "num_clusters = word_vectors.shape[0] / avg_word_per_cluster\n",
    "\n",
    "# Initalize a k-means object and use it to extract centroids\n",
    "print \"Running K means\"\n",
    "kmeans_clustering = KMeans( n_clusters = num_clusters, n_jobs=cores )\n",
    "idx = kmeans_clustering.fit_predict( word_vectors )\n",
    "\n",
    "# Get the end time and print how long the process took\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print \"Time taken for K Means clustering: \", elapsed, \"seconds.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.959446870775686"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elapsed/(60*60*24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a Word / Index dictionary, mapping each vocabulary word to\n",
    "# a cluster number\n",
    "word_centroid_map = dict(zip( model.index2word, idx ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print the first ten clusters\n",
    "for cluster in xrange(0,10):\n",
    "#\n",
    "    # Print the cluster number\n",
    "    print \"\\nCluster %d\" % cluster\n",
    "    #\n",
    "    # Find all of the words for that cluster number, and print them out\n",
    "    words = []\n",
    "    for i in xrange(0,len(word_centroid_map.values())):\n",
    "        if( word_centroid_map.values()[i] == cluster ):\n",
    "            words.append(word_centroid_map.keys()[i])\n",
    "    print words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'treadmil',\n",
       " u'toplantimiz',\n",
       " u'selanjutny',\n",
       " u'selanjut',\n",
       " u'kedpn',\n",
       " u'kalix',\n",
       " u'brsamaan',\n",
       " u'kaliny',\n",
       " u'ptama',\n",
       " u'brulang',\n",
       " u'mjls',\n",
       " u'kdatangan',\n",
       " u'prtmo',\n",
       " u'\\u4e88\\u7d04\\u6570',\n",
       " u'prtandingan',\n",
       " u'neveruary',\n",
       " u'pertame',\n",
       " u'mnggal',\n",
       " u'semntara',\n",
       " u\"d'dunia\",\n",
       " u'yaumil',\n",
       " u'brmula',\n",
       " u'tdie',\n",
       " u'ptma',\n",
       " u'mthri',\n",
       " u'kdpn',\n",
       " u'smpena',\n",
       " u'petama',\n",
       " u'dhari',\n",
       " u'bersm',\n",
       " u'slnjtnya',\n",
       " u'pertma',\n",
       " u'klinya',\n",
       " u'keduo',\n",
       " u'blnan',\n",
       " u'prtemuan',\n",
       " u'meninggl',\n",
       " u'\\u0628\\u0627\\u0644\\u0641\\u0644\\u0648\\u0628\\u0627\\u0643\\u0640',\n",
       " u'qiyam',\n",
       " u'bkumpul',\n",
       " u'prtmuan',\n",
       " u'tahn',\n",
       " u'daraja',\n",
       " u'nh\\xfck\\xfcmet',\n",
       " u'\\u307f\\u304f\\u3067\\u3059',\n",
       " u'berakhr',\n",
       " u'crah',\n",
       " u'slanjutnya',\n",
       " u'ksekian',\n",
       " u'berikutny',\n",
       " u'kedpan',\n",
       " u'brkhir',\n",
       " u'kdpan',\n",
       " u'diangka',\n",
       " u'diinfo',\n",
       " u'brikutnya',\n",
       " u'\\u062e\\u0640\\u0627\\u0635',\n",
       " u'tyng',\n",
       " u'brktnya',\n",
       " u'n\\u5c0f\\u8aac',\n",
       " u'kdepan',\n",
       " u'prtm',\n",
       " u'mpkt',\n",
       " u'ditgl',\n",
       " u'tnyt',\n",
       " u'mlwn',\n",
       " u'mlahirkan',\n",
       " u'ssdh',\n",
       " u'playanan',\n",
       " u'brikut',\n",
       " u'brtahun',\n",
       " u\"kali'a\",\n",
       " u'pemateri',\n",
       " u'swaktu',\n",
       " u'dmulai',\n",
       " u'prnikahan',\n",
       " u'depanny',\n",
       " u'penjualannya',\n",
       " u'smntr',\n",
       " u'kmenangan',\n",
       " u'kmdian',\n",
       " u'sngle',\n",
       " u'mrdeka',\n",
       " u'swtu',\n",
       " u'spakat',\n",
       " u'slnjutnya',\n",
       " u'jtbc\\uc5d0\\uc11c',\n",
       " u'ktiga',\n",
       " u'kdua',\n",
       " u'thnan',\n",
       " u'prgrm',\n",
       " u'tentatif']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kmeans-div-100.pkl',\n",
       " 'kmeans-div-100.pkl_01.npy',\n",
       " 'kmeans-div-100.pkl_02.npy']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#saving kmeans model\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(kmeans_clustering, 'kmeans-div-100.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_clf = joblib.load('kmeans-div-100.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
